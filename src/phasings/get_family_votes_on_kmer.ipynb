{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "PHASINGS_DIR='/home/groups/dpwall/briannac/alt_haplotypes/data/phasings/'\n",
    "BAM_MAPPINGS_FILE = '/home/groups/dpwall/briannac/general_data/bam_mappings.csv'\n",
    "KMER_COUNTS_FILE = '/home/groups/dpwall/briannac/alt_haplotypes/intermediate_files/kmers/kmers.0.tsv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in family region/global region conversion data.\n",
    "fam_region_to_idx = np.load(PHASINGS_DIR +  'fam_region_to_idx.npy', allow_pickle=True).item()\n",
    "idx_to_fam_region = np.load(PHASINGS_DIR +  'idx_to_fam_region.npy', allow_pickle=True).item()\n",
    "global_region_to_idx = np.load(PHASINGS_DIR +  'global_region_to_idx.npy', allow_pickle=True).item()\n",
    "idx_to_global_region = np.load(PHASINGS_DIR +  'idx_to_global_region.npy', allow_pickle=True).item()\n",
    "fam_region_to_global_region = np.load(PHASINGS_DIR + 'fam_regions_to_global_regions.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pipeline on a family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_mappings = pd.read_csv(BAM_MAPPINGS_FILE, sep='\\t', index_col=1)\n",
    "bam_mappings = bam_mappings[bam_mappings['status']=='Passed_QC_analysis_ready']\n",
    "sample_id_to_participant = {sample_id:participant_id for participant_id, sample_id in zip(bam_mappings.participant_id, bam_mappings.index)}\n",
    "\n",
    "fam_number = 1 #int(sys.argv[1])\n",
    "family_info = pd.read_pickle(PHASINGS_DIR + 'fam_list.df')\n",
    "fam = family_info.iloc[fam_number].fam\n",
    "mom = sample_id_to_participant[family_info.iloc[fam_number].mother_sample]\n",
    "dad = sample_id_to_participant[family_info.iloc[fam_number].father_sample]\n",
    "children = [sample_id_to_participant[s] for s in family_info.iloc[fam_number].sib_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-422c83c70a95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKMER_COUNTS_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mkmer_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkmer_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msample_id_to_participant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkmer_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \"\"\"\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_is_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_and_not_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for chunk in pd.read_table(KMER_COUNTS_FILE):\n",
    "    kmer_counts = chunk\n",
    "    break\n",
    "kmer_counts.columns = [sample_id_to_participant[c] for c in kmer_counts.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU1005202</th>\n",
       "      <th>AU1005302</th>\n",
       "      <th>AU1005301</th>\n",
       "      <th>AU1004202</th>\n",
       "      <th>AU1004301</th>\n",
       "      <th>AU0918302</th>\n",
       "      <th>AU0918202</th>\n",
       "      <th>AU0918301</th>\n",
       "      <th>AU0918201</th>\n",
       "      <th>AU0918303</th>\n",
       "      <th>...</th>\n",
       "      <th>AU4237201</th>\n",
       "      <th>AU4237202</th>\n",
       "      <th>AU4237303</th>\n",
       "      <th>AU4237304</th>\n",
       "      <th>AU4138202</th>\n",
       "      <th>AU3859201</th>\n",
       "      <th>AU3859202</th>\n",
       "      <th>AU3859303</th>\n",
       "      <th>AU3859301</th>\n",
       "      <th>AU3859302</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02C10540</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02C10540</th>\n",
       "      <td>02C10541</td>\n",
       "      <td>02C10542</td>\n",
       "      <td>02C10543</td>\n",
       "      <td>02C10702</td>\n",
       "      <td>02C10704</td>\n",
       "      <td>02C10855</td>\n",
       "      <td>02C10856</td>\n",
       "      <td>02C10857</td>\n",
       "      <td>02C10858</td>\n",
       "      <td>02C10859</td>\n",
       "      <td>...</td>\n",
       "      <td>MH0138051</td>\n",
       "      <td>MH0138052</td>\n",
       "      <td>MH0138054</td>\n",
       "      <td>MH0138055</td>\n",
       "      <td>MH0138989</td>\n",
       "      <td>MH0143008</td>\n",
       "      <td>MH0143009</td>\n",
       "      <td>MH0143013</td>\n",
       "      <td>MH0143018</td>\n",
       "      <td>MH0143019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22951</th>\n",
       "      <td>53783</td>\n",
       "      <td>18408</td>\n",
       "      <td>17742</td>\n",
       "      <td>4979</td>\n",
       "      <td>53161</td>\n",
       "      <td>83963</td>\n",
       "      <td>109072</td>\n",
       "      <td>101577</td>\n",
       "      <td>75124</td>\n",
       "      <td>87546</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AU1005202 AU1005302 AU1005301 AU1004202 AU1004301 AU0918302  \\\n",
       "02C10540                                                               \n",
       "02C10540  02C10541  02C10542  02C10543  02C10702  02C10704  02C10855   \n",
       "22951        53783     18408     17742      4979     53161     83963   \n",
       "0                0         0         0         0         0         0   \n",
       "0                0         0         0         0         0         0   \n",
       "0                0         0         0         0         0         0   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "0                0         0         0         0         0         0   \n",
       "0                0         0         0         0         0         0   \n",
       "0                0         0         0         0         0         0   \n",
       "0                0         0         0         0         0         0   \n",
       "0                0         0         0         0         0         0   \n",
       "\n",
       "         AU0918202 AU0918301 AU0918201 AU0918303  ...  AU4237201  AU4237202  \\\n",
       "02C10540                                          ...                         \n",
       "02C10540  02C10856  02C10857  02C10858  02C10859  ...  MH0138051  MH0138052   \n",
       "22951       109072    101577     75124     87546  ...        NaN        NaN   \n",
       "0                0         0         0         0  ...        NaN        NaN   \n",
       "0                0         0         0         0  ...        NaN        NaN   \n",
       "0                0         0         0         0  ...        NaN        NaN   \n",
       "...            ...       ...       ...       ...  ...        ...        ...   \n",
       "0                0         0         0         0  ...        NaN        NaN   \n",
       "0                0         0         0         0  ...        NaN        NaN   \n",
       "0                0         0         0         0  ...        NaN        NaN   \n",
       "0                0         0         0         0  ...        NaN        NaN   \n",
       "0                0         0         0         0  ...        NaN        NaN   \n",
       "\n",
       "          AU4237303  AU4237304  AU4138202  AU3859201  AU3859202  AU3859303  \\\n",
       "02C10540                                                                     \n",
       "02C10540  MH0138054  MH0138055  MH0138989  MH0143008  MH0143009  MH0143013   \n",
       "22951           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "0               NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "0               NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "0               NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "...             ...        ...        ...        ...        ...        ...   \n",
       "0               NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "0               NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "0               NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "0               NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "0               NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "          AU3859301  AU3859302  \n",
       "02C10540                        \n",
       "02C10540  MH0143018  MH0143019  \n",
       "22951           NaN     250845  \n",
       "0               NaN          0  \n",
       "0               NaN          0  \n",
       "0               NaN          0  \n",
       "...             ...        ...  \n",
       "0               NaN          0  \n",
       "0               NaN          0  \n",
       "0               NaN          0  \n",
       "0               NaN          0  \n",
       "0               NaN          0  \n",
       "\n",
       "[1000 rows x 4568 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmer_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['AU002203', 'AU002204', 'AU002205', 'AU002201', 'AU002202'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2b36700b55dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m######### Come up with possible phasings that correspond to k-mers #######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmer_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['AU002203', 'AU002204', 'AU002205', 'AU002201', 'AU002202'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "######### Come up with possible phasings that correspond to k-mers #######\n",
    "\n",
    "df_all = kmer_counts[np.append(children, [mom, dad])].copy()\n",
    "df_all[pd.isna(df_all)] = 0\n",
    "df_all = df_all>0\n",
    "\n",
    "# Impossible inheritance patterns, kmer is something weird.\n",
    "df_impossible = df_all[(df_all[mom]==False) & (df_all[dad]==False)] \n",
    "df_all = df_all[(df_all[mom]==True) | (df_all[dad]==True)]\n",
    "\n",
    "# Unclassifieable: Kmer is in all siblings, so parent could be homozygous kmer.\n",
    "df_unclassifiable = df_all[(df_all[children]).sum(axis=1)==len(children)]\n",
    "df_all = df_all[(df_all[children]).sum(axis=1)!=len(children)]\n",
    "\n",
    "df_all['kmer'] = df_all.index\n",
    "\n",
    "\n",
    "### Perform aggregation to get sets of sibs with shared maternal/paternal k-mer ####\n",
    "### Final index is {sibs_with_kmer, sibs_without_kmer}, value is kmers.\n",
    "# Extract maternally inherited, paternally inherited, and either inherited\n",
    "df_mat = df_all[(df_all[mom]==True) & (df_all[dad]==False)].drop([mom, dad], axis=1)\n",
    "df_pat = df_all[(df_all[mom]==False) & (df_all[dad]==True)].drop([mom, dad], axis=1)\n",
    "df_both = df_all[(df_all[mom]==True) & (df_all[dad]==True)].drop([mom, dad], axis=1)\n",
    "\n",
    "# Compute sib sets for maternally inherited.\n",
    "df_mat=df_mat.groupby(list(children)).aggregate(list) \n",
    "df_mat['sets'] = [frozenset([frozenset(children[np.where(np.array(i)==True)[0]]), frozenset(children[np.where(np.array(i)==False)[0]])]) for i in df_mat.index]\n",
    "df_mat = df_mat.groupby('sets').aggregate(lambda x: list(x))\n",
    "df_mat['kmer'] = [set(np.concatenate(k)) for k in df_mat['kmer']]\n",
    "df_mat['n_kmers'] = [len(k) for k in df_mat.kmer]\n",
    "\n",
    "# Compute sib sets for paternally inherited: \n",
    "df_pat=df_pat.groupby(list(children)).aggregate(list)\n",
    "df_pat['sets'] = [frozenset([frozenset(children[np.where(np.array(i)==True)[0]]), frozenset(children[np.where(np.array(i)==False)[0]])]) for i in df_pat.index]\n",
    "df_pat = df_pat.groupby('sets').aggregate(lambda x: list(x))\n",
    "df_pat['kmer'] = [set(np.concatenate(k)) for k in df_pat['kmer']]\n",
    "df_pat['n_kmers'] = [len(k) for k in df_pat.kmer]\n",
    "\n",
    "# Compute sib sets for both.  This has a slightly different structure: Index is [{sibs_with_kmer}, {sibs_without_kmer}]\n",
    "df_both=df_both.groupby(list(children)).aggregate(list)\n",
    "df_both['sets'] = [(frozenset(children[np.where(np.array(i)==True)[0]]), frozenset(children[np.where(np.array(i)==False)[0]])) for i in df_both.index]\n",
    "df_both = df_both.groupby('sets').aggregate(lambda x: list(x))\n",
    "df_both['kmer'] = [set(np.concatenate(k)) for k in df_both['kmer']]\n",
    "df_both['n_kmers'] = [len(k) for k in df_both.kmer]\n",
    "\n",
    "df_mat = df_mat.sort_values('n_kmers', ascending=False)\n",
    "df_pat = df_pat.sort_values('n_kmers', ascending=False)\n",
    "df_both = df_both.sort_values('n_kmers', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "phased_fam = pd.read_csv('/oak/stanford/groups/dpwall/users/kpaskov/PhasingFamilies/phased_ihart/%s.phased.txt' % fam, sep='\\t')\n",
    "phased_fam['region'] = ['%s.%i.%i' % (chrom.replace('chr', ''), int(i),int(j)) for chrom,i,j in zip(phased_fam.chrom, phased_fam.start_pos, phased_fam.end_pos)]\n",
    "phased_fam.drop([mom+'_mat', dad + '_mat', mom + '_pat', dad + '_pat'], axis=1, inplace=True)\n",
    "# Get phased groupings\n",
    "for i in children:\n",
    "    phased_fam[i] = [(i,j) for i,j in zip(phased_fam[i+'_mat'].replace(np.nan,-1), phased_fam[i+ '_pat'].replace(np.nan,-1))]\n",
    "    \n",
    "# Phased from mat groupings\n",
    "phased_fam_mat = phased_fam[[s for s in phased_fam.columns if 'mat' in s] + ['region']].groupby([s for s in phased_fam.columns if 'mat' in s]).aggregate(list)\n",
    "phased_fam_mat['sets'] = [(frozenset(children[np.where(np.array(i)==0)[0]]), frozenset(children[np.where(np.array(i)==1)[0]])) for i in phased_fam_mat.index]\n",
    "phased_fam_mat = phased_fam_mat.groupby('sets').aggregate(list)\n",
    "phased_fam_mat['region'] = [[i for j in k for i in j] for k in phased_fam_mat['region']]\n",
    "\n",
    "# Phased fam pat\n",
    "phased_fam_pat = phased_fam[[s for s in phased_fam.columns if 'pat' in s] + ['region']].groupby([s for s in phased_fam.columns if 'pat' in s]).aggregate(list)\n",
    "phased_fam_pat['sets'] = [(frozenset(children[np.where(np.array(i)==2)[0]]), frozenset(children[np.where(np.array(i)==3)[0]])) for i in phased_fam_pat.index]\n",
    "phased_fam_pat = phased_fam_pat.groupby('sets').aggregate(list)\n",
    "phased_fam_pat['region'] = [[i for j in k for i in j] for k in phased_fam_pat['region']]\n",
    "\n",
    "# Phased fam both\n",
    "phased_fam_both = phased_fam[list(children) + ['region']].groupby(list(children)).aggregate(list)\n",
    "\n",
    "\n",
    "# Process regions/kmers inherited from both/either parent. \n",
    "sample_name_to_num = {j:i for i,j in enumerate(phased_fam_both.index.names)}\n",
    "possible_regions_both = [[] for i in df_both.index]\n",
    "for i_kmer,child_with_kmer_index in enumerate(df_both.index):\n",
    "    possible_regions_ = []\n",
    "    \n",
    "    # Edge case where both parents have k-mer and no children do.\n",
    "    if len(child_with_kmer_index[0])==0:\n",
    "        for phased_fam_index,region in zip(phased_fam_both.index, phased_fam_both.region):\n",
    "            if (((1.0 not in {float(i[0]) for i in phased_fam_index}) or  (0.0 not in {float(i[0]) for i in phased_fam_index})) &\n",
    "                ((2.0 not in {float(i[1]) for i in phased_fam_index}) or  (3.0 not in {float(i[1]) for i in phased_fam_index}))):\n",
    "                possible_regions_ = possible_regions_ + region\n",
    "                \n",
    "    for phased_fam_index,region in zip(phased_fam_both.index, phased_fam_both.region):\n",
    "        if sum([phased_fam_index[sample_name_to_num[has_kmer]]==phased_fam_index[sample_name_to_num[no_kmer]] for has_kmer in child_with_kmer_index[0] for no_kmer in child_with_kmer_index[1]])==0:\n",
    "            possible_regions_ = possible_regions_ + region\n",
    "    possible_regions_both[i_kmer] = possible_regions_\n",
    "    \n",
    "# Process regions/kmers inherited from mom.\n",
    "sample_name_to_num = {j:i for i,j in enumerate(phased_fam_mat.index.names)}\n",
    "possible_regions_mat = [[] for i in df_mat.index]\n",
    "for i_kmer,child_with_kmer_index in enumerate(df_mat.index):\n",
    "    possible_regions_ = []\n",
    "    child_kmer_sets = list(child_with_kmer_index)\n",
    "    children_with_kmer = child_kmer_sets[0]\n",
    "    children_without_kmer = child_kmer_sets[1]\n",
    "    for phased_fam_index,region in zip(phased_fam_mat.index, phased_fam_mat.region):\n",
    "        child_set_1 = phased_fam_index[0]\n",
    "        child_set_2 = phased_fam_index[1]\n",
    "        if (\n",
    "            (len(child_set_1.difference(children_with_kmer))==0) & (len(child_set_2.difference(children_without_kmer))==0)\n",
    "        ) or (\n",
    "            (len(child_set_2.difference(children_with_kmer))==0) & (len(child_set_1.difference(children_without_kmer))==0)\n",
    "        ):\n",
    "            possible_regions_ = possible_regions_ + region\n",
    "    possible_regions_mat[i_kmer] = possible_regions_\n",
    "    \n",
    "# Process regions/kmers inherited from dad.\n",
    "sample_name_to_num = {j:i for i,j in enumerate(phased_fam_pat.index.names)}\n",
    "possible_regions_pat = [[] for i in df_pat.index]\n",
    "for i_kmer,child_with_kmer_index in enumerate(df_pat.index):\n",
    "    possible_regions_ = []\n",
    "    child_kmer_sets = list(child_with_kmer_index)\n",
    "    children_with_kmer = child_kmer_sets[0]\n",
    "    children_without_kmer = child_kmer_sets[1]\n",
    "    for phased_fam_index,region in zip(phased_fam_pat.index, phased_fam_pat.region):\n",
    "        child_set_1 = phased_fam_index[0]\n",
    "        child_set_2 = phased_fam_index[1]\n",
    "        if (\n",
    "            (len(child_set_1.difference(children_with_kmer))==0) & (len(child_set_2.difference(children_without_kmer))==0)\n",
    "        ) or (\n",
    "            (len(child_set_2.difference(children_with_kmer))==0) & (len(child_set_1.difference(children_without_kmer))==0)\n",
    "        ):\n",
    "            possible_regions_ = possible_regions_ + region\n",
    "    possible_regions_pat[i_kmer] = possible_regions_\n",
    "    \n",
    "    \n",
    "    \n",
    "##### Create family vote matrix #####\n",
    "family_vote = pd.DataFrame(np.zeros((len(kmer_counts), len(phased_fam.region)+2)))\n",
    "family_vote.columns = list(phased_fam.region) + ['impossible', 'ambigious']\n",
    "family_vote.index = kmer_counts.index\n",
    "family_vote.loc[df_impossible.index,'impossible']=1\n",
    "family_vote.loc[df_unclassifiable.index,'ambigious']=1\n",
    "for i in range(len(df_pat)):\n",
    "    family_vote.loc[df_pat.iloc[i].kmer, possible_regions_pat[i]] = 1\n",
    "for i in range(len(df_mat)):\n",
    "    family_vote.loc[df_mat.iloc[i].kmer, possible_regions_mat[i]] = 1\n",
    "for i in range(len(df_both)):\n",
    "    family_vote.loc[df_both.iloc[i].kmer, possible_regions_both[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match phasings to kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vote = np.zeros((len(kmer_counts), len(global_region_to_idx)))\n",
    "global_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3238440"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fam_region_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in family region/global region conversion data.\n",
    "with open('/home/groups/dpwall/briannac/alt_haplotypes/intermediate_files/phasings/' + 'fam_regions_to_global_regions_21.json', 'r') as f:\n",
    "    fam_regions_to_global_regions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASINGS_DIR='/home/groups/dpwall/briannac/alt_haplotypes/data/phasings/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in family region/global region conversion data.\n",
    "fam_region_to_idx = np.load(PHASINGS_DIR +  'fam_region_to_idx.npy', allow_pickle=True).item()\n",
    "idx_to_fam_region = np.load(PHASINGS_DIR +  'idx_to_fam_region.npy', allow_pickle=True).item()\n",
    "global_region_to_idx = np.load(PHASINGS_DIR +  'global_region_to_idx.npy', allow_pickle=True).item()\n",
    "idx_to_global_region = np.load(PHASINGS_DIR +  'idx_to_global_region.npy', allow_pickle=True).item()\n",
    "\n",
    "fam_region_to_global_region = np.load(PHASINGS_DIR + 'fam_regions_to_global_regions.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'global_region_to_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b02a1082c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_region_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'global_region_to_idx' is not defined"
     ]
    }
   ],
   "source": [
    "len(global_region_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create table/dictionary to convert family region to global region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in phased regions.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "FINAL_PHASINGS_DIR='/home/groups/dpwall/briannac/alt_haplotypes/data/phasings'\n",
    "\n",
    "\n",
    "start_ends = pd.read_pickle(FINAL_PHASINGS_DIR + '/family_regions.df')\n",
    "family_region_to_global_regions_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FINAL_PHASINGS_DIR + '/fam_regions_to_global_regions.json', 'w') as f:\n",
    "    json.dump(family_region_to_global_regions_dict, f)        \n",
    "        \n",
    "# Combine all dictionaries.\n",
    "#fam_regions_to_global_regions_full_dict = {}\n",
    "#for chrom in range(22):\n",
    "#    with open(PHASINGS_DIR + '/fam_regions_to_global_regions_%s.json' % chrom, 'r') as fp:\n",
    "#        new_dict = json.load(fp)\n",
    "#    fam_regions_to_global_regions_full_dict.update(new_dict)\n",
    "\n",
    "#with open(FINAL_PHASINGS_DIR + '/fam_regions_to_global_regions.json', 'w') as f:\n",
    "#    json.dump(family_region_to_global_regions_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n"
     ]
    }
   ],
   "source": [
    "print('saving...')\n",
    "with open(PHASINGS_DIR + '/fam_regions_to_global_regions_%s.json' % chrom, 'w') as f:\n",
    "    json.dump(family_region_to_global_regions_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = np.load('/home/groups/dpwall/briannac/alt_haplotypes/data/phasings/fam_regions_to_global_regions.npy', allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
